model: "simple_transformer"
base_config: "configs/base.yaml"
factors_config: "configs/factors.yaml"

trainer:
  batch_size: 256
  epochs: 50
  early_stop_patience: 10
  lr: 0.0005
  weight_decay: 0.0001
  lr_scheduler: "plateau"
  grad_clip: 1.0

simple_transformer:
  d_model: 128
  n_heads: 8
  depth: 3
  dropout: 0.1

loss:
  bce_weight: 1.0
  pinball_weight: 1.0
  use_focal: true
  focal_alpha: 0.75
  focal_gamma: 2.5

output_dir: "runs/simple_transformer"

